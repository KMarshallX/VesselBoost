{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3271cab5",
   "metadata": {},
   "source": [
    "# Vessel boost toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1323165",
   "metadata": {},
   "source": [
    "## 1. Initinal training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb4ec8",
   "metadata": {},
   "source": [
    "If you are working outside of a container, you can store you data under *data* folder as the instruction below. If you are working inside a container, you can mount your data folder to *./data/train/* and  *./data/label/*.\n",
    "\n",
    "Please make sure that the name of a segmentation image file should contain the FULL NAME of its corresponding MRI image. \n",
    "e.g.:\n",
    "\n",
    "**Raw image:** TOF_3895.nii.gz\n",
    "\n",
    "**Segmentation image:** seg_TOF_3895.nii.gz or TOF_3895_seg.nii.gz, just make sure it contains the \"TOF_3895\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0a2fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session will start shortly..\n",
      "Aborting the preprocessing procedure!\n",
      "\n",
      "All images have been loaded, the training process will start soon!\n",
      "Epoch: [1/10], Loss:  0.9851, Current learning rate:  0.00100000                \n",
      "Epoch: [2/10], Loss:  0.9758, Current learning rate:  0.00100000                \n",
      "Epoch: [3/10], Loss:  0.9773, Current learning rate:  0.00100000                \n",
      "Epoch: [4/10], Loss:  0.9739, Current learning rate:  0.00100000                \n",
      "Epoch: [5/10], Loss:  0.9742, Current learning rate:  0.00100000                \n",
      "Epoch: [6/10], Loss:  0.9698, Current learning rate:  0.00100000                \n",
      "Epoch: [7/10], Loss:  0.9688, Current learning rate:  0.00100000                \n",
      "Epoch: [8/10], Loss:  0.9691, Current learning rate:  0.00100000                \n",
      "Epoch: [9/10], Loss:  0.9880, Current learning rate:  0.00100000                \n",
      "Epoch: [10/10], Loss:  0.9725, Current learning rate:  0.00095000               \n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training finished! Please wait for the model to be saved!\n",
      "Model successfully saved! The location of the saved model is: ./../saved_models/test_model\n"
     ]
    }
   ],
   "source": [
    "# Set the necessary parameters\n",
    "# If you set prep_mode to 4, which means no preprocessing will happen, then you don't have to set a path to store the preprocessed images\n",
    "!python ./../train.py --ds_path ./../../data/img/ --lb_path ./../../data/seg/ --prep_mode 4 --ep 10 --lr 1e-3 --outmo ./../saved_models/test_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session will start shortly..\n",
      "The preprocessing procedure is starting!\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [03:19<00:00, 199.95s/it]\n",
      "All processed images are successfully saved!\n",
      "All images have been loaded, the training process will start soon!\n",
      "Epoch: [1/10], Loss:  0.9878, Current learning rate:  0.00100000                \n",
      "Epoch: [2/10], Loss:  0.9901, Current learning rate:  0.00100000                \n",
      "Epoch: [3/10], Loss:  0.9631, Current learning rate:  0.00100000                \n",
      "Epoch: [4/10], Loss:  0.9818, Current learning rate:  0.00100000                \n",
      "Epoch: [5/10], Loss:  0.9702, Current learning rate:  0.00100000                \n",
      "Epoch: [6/10], Loss:  0.9818, Current learning rate:  0.00095000                \n",
      "Epoch: [7/10], Loss:  0.9713, Current learning rate:  0.00095000                \n",
      "Epoch: [8/10], Loss:  0.9744, Current learning rate:  0.00095000                \n",
      "Epoch: [9/10], Loss:  0.9778, Current learning rate:  0.00090250                \n",
      "Epoch: [10/10], Loss:  0.9792, Current learning rate:  0.00090250               \n",
      "100%|███████████████████████████████████████████| 10/10 [00:06<00:00,  1.63it/s]\n",
      "Training finished! Please wait for the model to be saved!\n",
      "Model successfully saved! The location of the saved model is: ./../saved_models/test_model\n"
     ]
    }
   ],
   "source": [
    "# If you set prep_mode to 1,2 or 3, which means both/one of denosing and N4 bias field correction will happen, then you have to set a path to store the preprocessed images\n",
    "!python ./../train.py --ds_path ./../../data/img/ --lb_path ./../../data/seg/ --prep_mode 1 --ps_path ./../../data/preprocessed/ --ep 10 --lr 1e-3 --outmo ./../saved_models/test_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82ea5a",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070ee20",
   "metadata": {},
   "source": [
    "This is a stand-alone module to produce segmentation of input images by using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b45a87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference session will start shortly..\n",
      "Aborting the preprocessing procedure!\n",
      "\n",
      "Running with GPU\n",
      "Prediction procedure starts!\n",
      "100%|█████████████████████████████████████████████| 6/6 [01:10<00:00, 11.81s/it]\n",
      "Prediction procedure ends! Please wait for the post processing!\n",
      "Output processed GRE_3D_400um_TR20_FA18_TE7p5_14_sli52_FCY_GMP_BW200_32_biasCor.nii is successfully saved!\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/itee/uqmxu4/tor_env/lib/python3.11/site-packages/PIL/Image.py\", line 2408, in save\n",
      "    format = EXTENSION[ext]\n",
      "             ~~~~~~~~~^^^^^\n",
      "KeyError: ''\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/itee/uqmxu4/vessel_code/notebooks/./../inference.py\", line 54, in <module>\n",
      "    inference_postpo(threshold_vector[0], threshold_vector[1], pretrained_model, processed_data_list[i], mip_flag=True)\n",
      "  File \"/scratch/itee/uqmxu4/vessel_code/utils/module_utils.py\", line 202, in __call__\n",
      "    self.one_img_process(test_img_name, load_model, thresh, connect_thresh, mip_flag)\n",
      "  File \"/scratch/itee/uqmxu4/vessel_code/utils/module_utils.py\", line 186, in one_img_process\n",
      "    plt.imsave(save_mip_path_post, mip, cmap='gray')\n",
      "  File \"/scratch/itee/uqmxu4/tor_env/lib/python3.11/site-packages/matplotlib/pyplot.py\", line 2200, in imsave\n",
      "    return matplotlib.image.imsave(fname, arr, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/itee/uqmxu4/tor_env/lib/python3.11/site-packages/matplotlib/image.py\", line 1689, in imsave\n",
      "    image.save(fname, **pil_kwargs)\n",
      "  File \"/scratch/itee/uqmxu4/tor_env/lib/python3.11/site-packages/PIL/Image.py\", line 2411, in save\n",
      "    raise ValueError(msg) from e\n",
      "ValueError: unknown file extension: \n"
     ]
    }
   ],
   "source": [
    "# Set the necessary parameters\n",
    "# If you set prep_mode to 4, which means no preprocessing will happen, then you don't have to set a path to store the preprocessed images\n",
    "!python ./../inference.py --ds_path ./../../data/img/ --out_path ./../../data/predicted_label/ --pretrained ./../saved_models/test_model --prep_mode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb55f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you set prep_mode to 1,2 or 3, which means both/one of denosing and N4 bias field correction will happen, then you have to set a path to store the preprocessed images\n",
    "!python ./../2_inference.py --ds_path ./../data/train/ --out_path ./../data/predicted_label/ --pretrained ./../models-tests --prep_mode 1 --ps_path ./../data/preprocessed_data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dda4a9",
   "metadata": {},
   "source": [
    "## 3. Test-time adaptation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da245f6",
   "metadata": {},
   "source": [
    "Test-time adaptation module for further optimization of a pre-trained model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf325dd9",
   "metadata": {},
   "source": [
    "### Pre-trained models promptly available on OSF\n",
    "\n",
    "We are currently provide 3 pre-trained models, you can download them to make infetence on your images by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572f6a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/qbi/uqfribe1/postdoc/vessel_code/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40671286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0.00/26.4M [00:00<?, ?bytes/s]\r\n",
      " 10%|▉         | 2.61M/26.4M [00:00<00:00, 26.0Mbytes/s]\r\n",
      " 88%|████████▊ | 23.2M/26.4M [00:00<00:00, 132Mbytes/s] \r\n",
      "100%|██████████| 26.4M/26.4M [00:00<00:00, 123Mbytes/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir ./../saved_models\n",
    "\n",
    "cd ./../saved_models/\n",
    "osf -p jg7cr fetch /saved_models/Init_ep1000_lr1e3_tver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f320dd",
   "metadata": {},
   "source": [
    "### TODO: TTA without a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759a58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4578904b",
   "metadata": {},
   "source": [
    "### TODO: TTA with a specified proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5923f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
