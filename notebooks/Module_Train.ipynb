{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vessel Boost Toolbox**\n",
    "## Module - train.py\n",
    "Vessel Boost toolbox provides a training module which allows you to train your own initial weights based on UNET-3D architecture [Çiçek, Ö., et al. (2016)]. \\\n",
    "\\\n",
    "If you are working outside of a container, you can store you data under data folder as the instruction below.\\\n",
    "If you are working inside a container, you can mount your data folder to _./data/image/_ and _./data/label/_ \\\n",
    "\\\n",
    "For using this training module, you should store your base data images and the segmentations in two folders, e.g. store your images in _./data/image/_ and store the corresponding segmentations in _./data/label/_\\\n",
    "Also please make sure that the names of your base segmentations contain the **FULL NAME** of the corresponding image files. e.g.:\\\n",
    "\\\n",
    "**Raw Image**: TOF_3895.nii.gz\\\n",
    "**Base Segmentation**: seg_TOF_3895.nii.gz or TOF_3895_seg.nii.gz, just make sure it contains the \"TOF_3895\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example notebook, we also provide a public MR image data and its segmentation to demonstrate the usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 327M/327M [00:01<00:00, 174Mbytes/s]\n",
      "100%|█████████████████████████████████████| 327M/327M [00:01<00:00, 179Mbytes/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "!osf -p nr6gc fetch /osfstorage/twoEchoTOF/raw/GRE_3D_400um_TR20_FA18_TE7p5_14_sli52_FCY_GMP_BW200_32.nii ./../../data/img/example_image.nii\n",
    "!osf -p nr6gc fetch /osfstorage/twoEchoTOF/seg/seg_GRE_3D_400um_TR20_FA18_TE7p5_14_sli52_FCY_GMP_BW200_32_biasCor_H75_L55_C10.nii ./../../data/seg/seg_example_image.nii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without preprocessing \n",
    "If you set argument *-prep_mode* to 4, then no preprocessing (N4 bias field correction, denoising) will happen, and you don't need to set a path specificly to store the preprocessed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session will start shortly..\n",
      "Aborting the preprocessing procedure!\n",
      "\n",
      "Epoch: [1/10], Loss:  0.9849, Current learning rate:  0.00100000                \n",
      "Epoch: [2/10], Loss:  0.9674, Current learning rate:  0.00100000                \n",
      "Epoch: [3/10], Loss:  0.9902, Current learning rate:  0.00100000                \n",
      "Epoch: [4/10], Loss:  0.9823, Current learning rate:  0.00100000                \n",
      "Epoch: [5/10], Loss:  0.9735, Current learning rate:  0.00095000                \n",
      "Epoch: [6/10], Loss:  0.9739, Current learning rate:  0.00095000                \n",
      "Epoch: [7/10], Loss:  0.9901, Current learning rate:  0.00095000                \n",
      "Epoch: [8/10], Loss:  0.9980, Current learning rate:  0.00090250                \n",
      "Epoch: [9/10], Loss:  0.9857, Current learning rate:  0.00090250                \n",
      "Epoch: [10/10], Loss:  0.9759, Current learning rate:  0.00090250               \n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.15s/it]\n",
      "Training finished! Please wait for the model to be saved!\n",
      "\n",
      "Model successfully saved! The location of the saved model is: ./../saved_models/test_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./../train.py --ds_path ./../../data/img/ --lb_path ./../../data/seg/ --prep_mode 4 --ep 10 --lr 1e-3 --outmo ./../saved_models/test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With preprocessing\n",
    "If you set prep_mode to 1,2 or 3, which means both or one of denosing and N4 bias field correction will happen, then you have to set a path to store the preprocessed images e.g. *-ps_path ./data/preprocessed/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session will start shortly..\n",
      "The preprocessing procedure is starting!\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [03:14<00:00, 194.11s/it]\n",
      "All processed images are successfully saved!\n",
      "Epoch: [1/10], Loss:  0.9809, Current learning rate:  0.00100000                \n",
      "Epoch: [2/10], Loss:  0.9844, Current learning rate:  0.00100000                \n",
      "Epoch: [3/10], Loss:  0.9861, Current learning rate:  0.00100000                \n",
      "Epoch: [4/10], Loss:  0.9575, Current learning rate:  0.00100000                \n",
      "Epoch: [5/10], Loss:  0.9798, Current learning rate:  0.00100000                \n",
      "Epoch: [6/10], Loss:  0.9675, Current learning rate:  0.00100000                \n",
      "Epoch: [7/10], Loss:  0.9797, Current learning rate:  0.00095000                \n",
      "Epoch: [8/10], Loss:  0.9731, Current learning rate:  0.00095000                \n",
      "Epoch: [9/10], Loss:  0.9632, Current learning rate:  0.00095000                \n",
      "Epoch: [10/10], Loss:  0.9717, Current learning rate:  0.00090250               \n",
      "100%|███████████████████████████████████████████| 10/10 [00:06<00:00,  1.64it/s]\n",
      "Training finished! Please wait for the model to be saved!\n",
      "\n",
      "Model successfully saved! The location of the saved model is: ./../saved_models/test_model_prep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./../train.py --ds_path ./../../data/img/ --lb_path ./../../data/seg/ --prep_mode 1 --ps_path ./../../data/preprocessed/ --ep 10 --lr 1e-3 --outmo ./../saved_models/test_model_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please be noted:\n",
    "In normal cases, the loss value will drop below 0.4000 as we're using Tversky loss metric. However, in this tutorial notebook, we set the training epoch to an extremely low number just to demonstrate the usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
