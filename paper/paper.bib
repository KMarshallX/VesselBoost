
@article{hanke_high-resolution_2014,
	title = {A high-resolution 7-{Tesla} {fMRI} dataset from complex natural stimulation with an audio movie},
	volume = {1},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata20143},
	doi = {10.1038/sdata.2014.3},
	abstract = {Abstract
            Here we present a high-resolution functional magnetic resonance (fMRI) dataset – 20 participants recorded at high field strength (7 Tesla) during prolonged stimulation with an auditory feature film (“Forrest Gump”). In addition, a comprehensive set of auxiliary data (T1w, T2w, DTI, susceptibility-weighted image, angiography) as well as measurements to assess technical and physiological noise components have been acquired. An initial analysis confirms that these data can be used to study common and idiosyncratic brain response patterns to complex auditory stimulation. Among the potential uses of this dataset are the study of auditory attention and cognition, language and music perception, and social perception. The auxiliary measurements enable a large variety of additional analysis strategies that relate functional response patterns to structural properties of the brain. Alongside the acquired data, we provide source code and detailed information on all employed procedures – from stimulus creation to data analysis. In order to facilitate replicative and derived works, only free and open-source software was utilized.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Scientific Data},
	author = {Hanke, Michael and Baumgartner, Florian J. and Ibe, Pierre and Kaule, Falko R. and Pollmann, Stefan and Speck, Oliver and Zinke, Wolf and Stadler, Jörg},
	month = may,
	year = {2014},
	pages = {140003},
	file = {Hanke et al. - 2014 - A high-resolution 7-Tesla fMRI dataset from comple.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/IQAUDYJ2/Hanke et al. - 2014 - A high-resolution 7-Tesla fMRI dataset from comple.pdf:application/pdf},
}

@article{tustison_n4itk_2010,
	title = {{N4ITK}: {Improved} {N3} {Bias} {Correction}},
	volume = {29},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{N4ITK}},
	url = {http://ieeexplore.ieee.org/document/5445030/},
	doi = {10.1109/TMI.2010.2046908},
	abstract = {A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as “N4ITK,” available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized 3 He lung image data, and 9.4T postmortem hippocampus data.},
	language = {en},
	number = {6},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tustison, Nicholas J and Avants, Brian B and Cook, Philip A and {Yuanjie Zheng} and Egan, Alexander and Yushkevich, Paul A and Gee, James C},
	month = jun,
	year = {2010},
	pages = {1310--1320},
	file = {Tustison et al. - 2010 - N4ITK Improved N3 Bias Correction.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/YDHPPXS7/Tustison et al. - 2010 - N4ITK Improved N3 Bias Correction.pdf:application/pdf},
}

@article{forstmann_multi-modal_2014,
	title = {Multi-modal ultra-high resolution structural 7-{Tesla} {MRI} data repository},
	volume = {1},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201450},
	doi = {10.1038/sdata.2014.50},
	abstract = {Abstract
            Structural brain data is key for the understanding of brain function and networks, i.e., connectomics. Here we present data sets available from the ‘atlasing of the basal ganglia (ATAG)’ project, which provides ultra-high resolution 7 Tesla (T) magnetic resonance imaging (MRI) scans from young, middle-aged, and elderly participants. The ATAG data set includes whole-brain and reduced field-of-view MP2RAGE and T2*-weighted scans of the subcortex and brainstem with ultra-high resolution at a sub-millimeter scale. The data can be used to develop new algorithms that help building high-resolution atlases both relevant for the basic and clinical neurosciences. Importantly, the present data repository may also be used to inform the exact positioning of electrodes used for deep-brain-stimulation in patients with Parkinson’s disease and neuropsychiatric diseases.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Scientific Data},
	author = {Forstmann, Birte U and Keuken, Max C and Schafer, Andreas and Bazin, Pierre-Louis and Alkemade, Anneke and Turner, Robert},
	month = dec,
	year = {2014},
	pages = {140050},
	file = {Forstmann et al. - 2014 - Multi-modal ultra-high resolution structural 7-Tes.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/5YCSRRCU/Forstmann et al. - 2014 - Multi-modal ultra-high resolution structural 7-Tes.pdf:application/pdf},
}

@inproceedings{cicek_2016,
	address = {Cham},
	title = {{3D} {U}-{Net}: {Learning} {Dense} {Volumetric} {Segmentation} from {Sparse} {Annotation}},
	volume = {9901},
	isbn = {978-3-319-46722-1 978-3-319-46723-8},
	shorttitle = {{3D} {U}-{Net}},
	url = {https://link.springer.com/10.1007/978-3-319-46723-8_49},
	abstract = {This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-ﬂy elastic deformations for eﬃcient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2016},
	publisher = {Springer International Publishing},
	author = {Çiçek, Özgün and Abdulkadir, Ahmed and Lienkamp, Soeren S. and Brox, Thomas and Ronneberger, Olaf},
	editor = {Ourselin, Sebastien and Joskowicz, Leo and Sabuncu, Mert R. and Unal, Gozde and Wells, William},
	year = {2016},
	doi = {10.1007/978-3-319-46723-8_49},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {424--432},
	file = {Çiçek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation f.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/BYEETFIM/Çiçek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation f.pdf:application/pdf},
}

@inproceedings{paszke_automatic_2017,
	address = {California},
	title = {Automatic differentiation in {PyTorch}},
	abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
	language = {en},
	booktitle = {{NIPS} 2017 {Autodiff} {Workshop}},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year = {2017},
	file = {Paszke et al. - Automatic differentiation in PyTorch.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/9IVE5RW5/Paszke et al. - Automatic differentiation in PyTorch.pdf:application/pdf},
}

@inproceedings{salehi_tversky_2017,
	title = {Tversky loss function for image segmentation using {3D} fully convolutional deep networks},
	url = {http://arxiv.org/abs/1706.05721},
	abstract = {Fully convolutional deep neural networks carry out excellent potential for fast and accurate image segmentation. One of the main challenges in training these networks is data imbalance, which is particularly problematic in medical imaging applications such as lesion segmentation where the number of lesion voxels is often much lower than the number of non-lesion voxels. Training with unbalanced data can lead to predictions that are severely biased towards high precision but low recall (sensitivity), which is undesired especially in medical applications where false negatives are much less tolerable than false positives. Several methods have been proposed to deal with this problem including balanced sampling, two step training, sample re-weighting, and similarity loss functions. In this paper, we propose a generalized loss function based on the Tversky index to address the issue of data imbalance and achieve much better trade-oﬀ between precision and recall in training 3D fully convolutional deep neural networks. Experimental results in multiple sclerosis lesion segmentation on magnetic resonance images show improved F2 score, Dice coeﬃcient, and the area under the precision-recall curve in test data. Based on these results we suggest Tversky loss function as a generalized framework to eﬀectively train deep neural networks.},
	language = {en},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Salehi, Seyed Sadegh Mohseni and Erdogmus, Deniz and Gholipour, Ali},
	year = {2017},
	note = {arXiv:1706.05721 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Salehi et al. - 2017 - Tversky loss function for image segmentation using.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/HCZUYGEC/Salehi et al. - 2017 - Tversky loss function for image segmentation using.pdf:application/pdf},
}

@article{chatterjee_ds6_2022,
	title = {{DS6}, {Deformation}-{Aware} {Semi}-{Supervised} {Learning}: {Application} to {Small} {Vessel} {Segmentation} with {Noisy} {Training} {Data}},
	volume = {8},
	issn = {2313-433X},
	shorttitle = {{DS6}, {Deformation}-{Aware} {Semi}-{Supervised} {Learning}},
	url = {https://www.mdpi.com/2313-433X/8/10/259},
	doi = {10.3390/jimaging8100259},
	abstract = {Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer’s disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi’s vessel enhancement with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them timeconsuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 ± 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.},
	language = {en},
	number = {10},
	urldate = {2023-07-26},
	journal = {Journal of Imaging},
	author = {Chatterjee, Soumick and Prabhu, Kartik and Pattadkal, Mahantesh and Bortsova, Gerda and Sarasaen, Chompunuch and Dubost, Florian and Mattern, Hendrik and De Bruijne, Marleen and Speck, Oliver and Nürnberger, Andreas},
	month = sep,
	year = {2022},
	pages = {259},
	file = {Chatterjee et al. - 2022 - DS6, Deformation-Aware Semi-Supervised Learning A.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/FDQCXP5K/Chatterjee et al. - 2022 - DS6, Deformation-Aware Semi-Supervised Learning A.pdf:application/pdf},
}

@article{manjon_adaptive_2010,
	title = {Adaptive non-local means denoising of {MR} images with spatially varying noise levels: {Spatially} {Adaptive} {Nonlocal} {Denoising}},
	volume = {31},
	issn = {10531807},
	shorttitle = {Adaptive non-local means denoising of {MR} images with spatially varying noise levels},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jmri.22003},
	doi = {10.1002/jmri.22003},
	abstract = {Purpose: To adapt the so-called nonlocal means ﬁlter to deal with magnetic resonance (MR) images with spatially varying noise levels (for both Gaussian and Rician distributed noise). Materials and Methods: Most ﬁltering techniques assume an equal noise distribution across the image. When this assumption is not met, the resulting ﬁltering becomes suboptimal. This is the case of MR images with spatially varying noise levels, such as those obtained by parallel imaging (sensitivity-encoded), intensity inhomogeneity-corrected images, or surface coil-based acquisitions. We propose a new method where information regarding the local image noise level is used to adjust the amount of denoising strength of the ﬁlter. Such information is automatically obtained from the images using a new local noise estimation method.
Results: The proposed method was validated and compared with the standard nonlocal means ﬁlter on simulated and real MRI data showing an improved performance in all cases.
Conclusion: The new noise-adaptive method was demonstrated to outperform the standard ﬁlter when spatially varying noise is present in the images.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Manjón, José V. and Coupé, Pierrick and Martí-Bonmatí, Luis and Collins, D. Louis and Robles, Montserrat},
	month = jan,
	year = {2010},
	pages = {192--203},
	file = {Manjón et al. - 2010 - Adaptive non-local means denoising of MR images wi.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/BC4I6IX9/Manjón et al. - 2010 - Adaptive non-local means denoising of MR images wi.pdf:application/pdf},
}

@software{silversmith:2021,
  author       = {Silversmith, William},
  title        = {{cc3d: Connected components on multilabel 3D \& 2D 
                   images.}},
  month        = sep,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {3.2.1},
  doi          = {10.5281/zenodo.5719536},
  url          = {https://doi.org/10.5281/zenodo.5719536}
}


@article{mattern_prospective_2018,
	title = {Prospective motion correction enables highest resolution time-of-flight angiography at {7T}: {Prospectively} {Motion}-{Corrected} {TOF} {Angiography} at {7T}},
	volume = {80},
	issn = {07403194},
	shorttitle = {Prospective motion correction enables highest resolution time-of-flight angiography at {7T}},
	url = {http://doi.wiley.com/10.1002/mrm.27033},
	doi = {10.1002/mrm.27033},
	abstract = {Purpose: Higher magnetic field strengths enable time-of-flight (TOF) angiography with higher resolution to depict smallvessel pathologies. However, this potential is limited by the subject’s ability to remain motionless. Even small-scale, involuntary motion can degrade vessel depiction, thus limiting the effective resolution. The aim of this study was to overcome this resolution limit by deploying prospectively motioncorrected (PMC) TOF.
Methods: An optical, marker-based, in-bore tracking system was used to update the imaging volume prospectively according to the subject’s head motion. PMC TOF was evaluated in 12 healthy, cooperative subjects at isotropic resolution of up to 150 mm. Image quality was assessed qualitatively through reader rating and quantitatively with the average edge-strength metric.
Results: PMC significantly increased the average edge strength and qualitatively improved the vessel depiction in nine out of 11 cases. Image quality was never degraded by motion correction. PMC also enabled acquisition of the highest resolution human brain in vivo TOF angiography to date.
Conclusion: With PMC enabled, high-resolution TOF is able to visualize brain vasculature beyond the effective resolution limit. Magn Reson Med 80:248–258, 2018. VC 2017 International Society for Magnetic Resonance in Medicine.},
	language = {en},
	number = {1},
	urldate = {2020-01-23},
	journal = {Magnetic Resonance in Medicine},
	author = {Mattern, Hendrik and Sciarra, Alessandro and Godenschweger, Frank and Stucht, Daniel and Lüsebrink, Falk and Rose, Georg and Speck, Oliver},
	month = jul,
	year = {2018},
	pages = {248--258},
	file = {Mattern et al. - 2018 - Prospective motion correction enables highest reso.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\JEPBJFLD\\Mattern et al. - 2018 - Prospective motion correction enables highest reso.pdf:application/pdf},
}

@article{bollmann_imaging_2022,
	title = {Imaging of the pial arterial vasculature of the human brain in vivo using high-resolution {7T} time-of-flight angiography},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.71186},
	doi = {10.7554/eLife.71186},
	abstract = {The pial arterial vasculature of the human brain is the only blood supply to the neocortex, but quantitative data on the morphology and topology of these mesoscopic arteries (diameter 50-300µm) remains scarce. Because it is commonly assumed that blood flow velocities in these vessels are prohibitively slow, non-invasive time-of-flight MRI angiography (TOF-MRA)-which is well-suited to high 3D imaging resolutions-has not been applied to imaging the pial arteries. Here, we provide a theoretical framework that outlines how TOF-MRA can visualize small pial arteries in vivo, by employing extremely small voxels at the size of individual vessels. We then provide evidence for this theory by imaging the pial arteries at 140-µm isotropic resolution using a 7T MRI scanner and prospective motion correction, and show that pial arteries one voxel-width in diameter can be detected. We conclude that imaging pial arteries is not limited by slow blood flow, but instead by achievable image resolution. This study represents the first targeted, comprehensive account of imaging pial arteries in vivo in the human brain. This ultra-high-resolution angiography will enable the characterization of pial vascular anatomy across the brain to investigate patterns of blood supply and relationships between vascular and functional architecture.},
	urldate = {2022-05-13},
	journal = {eLife},
	author = {Bollmann, Saskia and Mattern, Hendrik and Bernier, Michaël and Robinson, Simon D and Park, Daniel J and Speck, Oliver and Polimeni, Jonathan R},
	editor = {Jbabdi, Saad},
	month = apr,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e71186},
	file = {Bollmann et al. - 2022 - Author - file.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\R8YLNFAY\\Bollmann et al. - 2022 - Imaging of the pial arterial vasculature of the hu.pdf:application/pdf;Bollmann et al. - 2022 - Imaging of the pial arterial vasculature of the hu.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\ZVFFKIRG\\Bollmann et al. - 2022 - Imaging of the pial arterial vasculature of the hu.pdf:application/pdf},
}

@article{lucena_convolutional_2019,
	title = {Convolutional neural networks for skull-stripping in brain {MR} imaging using silver standard masks},
	volume = {98},
	issn = {0933-3657},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365718305177},
	doi = {10.1016/j.artmed.2019.06.008},
	abstract = {Manual annotation is considered to be the “gold standard” in medical imaging analysis. However, medical imaging datasets that include expert manual segmentation are scarce as this step is time-consuming, and therefore expensive. Moreover, single-rater manual annotation is most often used in data-driven approaches making the network biased to only that single expert. In this work, we propose a CNN for brain extraction in magnetic resonance (MR) imaging, that is fully trained with what we refer to as “silver standard” masks. Therefore, eliminating the cost associated with manual annotation. Silver standard masks are generated by forming the consensus from a set of eight, public, non-deep-learning-based brain extraction methods using the Simultaneous Truth and Performance Level Estimation (STAPLE) algorithm. Our method consists of (1) developing a dataset with “silver standard” masks as input, and implementing (2) a tri-planar method using parallel 2D U-Net-based convolutional neural networks (CNNs) (referred to as CONSNet). This term refers to our integrated approach, i.e., training with silver standard masks and using a 2D U-Net-based architecture. We conducted our analysis using three public datasets: the Calgary-Campinas-359 (CC-359), the LONI Probabilistic Brain Atlas (LPBA40), and the Open Access Series of Imaging Studies (OASIS). Five performance metrics were used in our experiments: Dice coefficient, sensitivity, specificity, Hausdorff distance, and symmetric surface-to-surface mean distance. Our results showed that we outperformed (i.e., larger Dice coefficients) the current state-of-the-art skull-stripping methods without using gold standard annotation for the CNNs training stage. CONSNet is the first deep learning approach that is fully trained using silver standard data and is, thus, more generalizable. Using these masks, we eliminate the cost of manual annotation, decreased inter-/intra-rater variability, and avoided CNN segmentation overfitting towards one specific manual annotation guideline that can occur when gold standard masks are used. Moreover, once trained, our method takes few seconds to process a typical brain image volume using modern a high-end GPU. In contrast, many of the other competitive methods have processing times in the order of minutes.},
	language = {en},
	urldate = {2021-07-24},
	journal = {Artificial Intelligence in Medicine},
	author = {Lucena, Oeslle and Souza, Roberto and Rittner, Letícia and Frayne, Richard and Lotufo, Roberto},
	month = jul,
	year = {2019},
	pages = {48--58},
	file = {Lucena et al. - 2019 - Convolutional neural networks for skull-stripping .pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\T2VUKM89\\Lucena et al. - 2019 - Convolutional neural networks for skull-stripping .pdf:application/pdf},
}

@article{hetts_pial_2017,
	title = {Pial {Artery} {Supply} as an {Anatomic} {Risk} {Factor} for {Ischemic} {Stroke} in the {Treatment} of {Intracranial} {Dural} {Arteriovenous} {Fistulas}},
	volume = {38},
	issn = {0195-6108, 1936-959X},
	url = {http://www.ajnr.org/lookup/doi/10.3174/ajnr.A5396},
	doi = {10.3174/ajnr.A5396},
	abstract = {BACKGROUND AND PURPOSE: Although intracranial dural arteriovenous ﬁstulas are principally supplied by dural branches of the external carotid, internal carotid, and vertebral arteries, they can also be fed by pial arteries that supply the brain. We sought to determine the frequency of neurologic deﬁcits following treatment of intracranial dural arteriovenous ﬁstulas with and without pial artery supply. MATERIALS AND METHODS: One hundred twenty-two consecutive patients who underwent treatment for intracranial dural arteriovenous ﬁstulas at our hospital from 2008 to 2015 were retrospectively reviewed. Patient data were examined for posttreatment neurologic deﬁcits; patients with such deﬁcits were evaluated for imaging evidence of cerebral infarction. Data were analyzed with multivariable logistic regression.
RESULTS: Of 122 treated patients, 29 (23.8\%) had dural arteriovenous ﬁstulas with pial artery supply and 93 (76.2\%) had dural arteriovenous ﬁstulas without pial arterial supply. Of patients with pial artery supply, 4 (13.8\%) had posttreatment neurologic deﬁcits, compared with 2 patients (2.2\%) without pial artery supply (P ϭ .04). Imaging conﬁrmed that 3 patients with pial artery supply (10.3\%) had cerebral infarcts, compared with only 1 patient without pial artery supply (1.1\%, P ϭ .03). Increasing patient age was also positively associated with pial supply and treatment-related complications.
CONCLUSIONS: Patients with dural arteriovenous ﬁstulas supplied by the pial arteries were more likely to experience posttreatment complications, including ischemic strokes, than patients with no pial artery supply. The approach to dural arteriovenous ﬁstula treatment should be made on a case-by-case basis so that the risk of complications can be minimized.},
	language = {en},
	number = {12},
	urldate = {2020-05-06},
	journal = {American Journal of Neuroradiology},
	author = {Hetts, S.W. and Yen, A. and Cooke, D.L. and Nelson, J. and Jolivalt, P. and Banaga, J. and Amans, M.R. and Dowd, C.F. and Higashida, R.T. and Lawton, M.T. and Kim, H. and Halbach, V.V.},
	month = dec,
	year = {2017},
	pages = {2315--2320},
	file = {Hetts et al. - 2017 - Pial Artery Supply as an Anatomic Risk Factor for .pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\S67TBQT4\\Hetts et al. - 2017 - Pial Artery Supply as an Anatomic Risk Factor for .pdf:application/pdf},
}

@article{mcconnell_cerebral_2016,
	title = {Cerebral microcirculatory failure after subarachnoid hemorrhage is reversed by hyaluronidase},
	volume = {36},
	issn = {0271-678X, 1559-7016},
	url = {http://journals.sagepub.com/doi/10.1177/0271678X15608389},
	doi = {10.1177/0271678X15608389},
	abstract = {Aneurysmal subarachnoid hemorrhage remains one of the more devastating forms of stroke due in large part to delayed cerebral ischemia that appears days to weeks following the initial hemorrhage. Therapies exclusively targeting large caliber arterial vasospasm have fallen short, and thus we asked whether capillary dysfunction contributes to delayed cerebral ischemia after subarachnoid hemorrhage. Using a mouse model of subarachnoid hemorrhage and two-photon microscopy we showed capillary dysfunction unrelated to upstream arterial constriction. Subarachnoid hemorrhage decreased RBC velocity by 30\%, decreased capillary pulsatility by 50\%, and increased length of non-perfusing capillaries by 15\%. This was accompanied by severe brain hypoxia and neuronal loss. Hyaluronidase, an enzyme that alters capillary blood flow by removing the luminal glycocalyx, returned RBC velocity and pulsatility to normal. Hyaluronidase also reversed brain hypoxia and prevented neuron loss typically seen after subarachnoid hemorrhage. Thus, subarachnoid hemorrhage causes specific changes in capillary RBC flow independent of arterial spasm, and hyaluronidase treatment that normalizes capillary blood flow can prevent brain hypoxia and injury after subarachnoid hemorrhage. Prevention or treatment of capillary dysfunction after subarachnoid hemorrhage may reduce the incidence or severity of subarachnoid hemorrhage-induced delayed cerebral ischemia.},
	language = {en},
	number = {9},
	urldate = {2020-05-06},
	journal = {Journal of Cerebral Blood Flow \& Metabolism},
	author = {McConnell, Evan D and Wei, Helen S and Reitz, Katherine M and Kang, Hongyi and Takano, Takahiro and Vates, G Edward and Nedergaard, Maiken},
	month = sep,
	year = {2016},
	pages = {1537--1552},
	file = {McConnell et al. - 2016 - Cerebral microcirculatory failure after subarachno.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\BI8FF33M\\McConnell et al. - 2016 - Cerebral microcirculatory failure after subarachno.pdf:application/pdf},
}

@article{park_quantification_2020,
	title = {Quantification of blood flow patterns in the cerebral arterial circulation of individual (human) subjects},
	volume = {36},
	issn = {2040-7939, 2040-7947},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cnm.3288},
	doi = {10.1002/cnm.3288},
	abstract = {There is a growing research interest in quantifying blood flow distribution for the entire cerebral circulation to sharpen diagnosis and improve treatment options for cerebrovascular disease of individual patients. We present a methodology to reconstruct subject-specific cerebral blood flow patterns in accordance with physiological and fluid mechanical principles and optimally informed by in vivo neuroimage data of cerebrovascular anatomy and arterial blood flow rates. We propose an inverse problem to infer blood flow distribution across the visible portion of the arterial network that best matches subject-specific anatomy and a given set of volumetric flow measurements. The optimization technique also mitigates the effect of uncertainties by reconciling incomplete flow data and by dissipating unavoidable acquisition errors associated with medical imaging data.},
	language = {en},
	number = {1},
	urldate = {2020-04-21},
	journal = {International Journal for Numerical Methods in Biomedical Engineering},
	author = {Park, Chang S. and Hartung, Grant and Alaraj, Ali and Du, Xinjian and Charbel, Fady T. and Linninger, Andreas A.},
	month = jan,
	year = {2020},
	file = {Park et al. - 2020 - Quantification of blood flow patterns in the cereb.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\4ZLFLY9Y\\Park et al. - 2020 - Quantification of blood flow patterns in the cereb.pdf:application/pdf},
}

@article{ii_multiscale_2020,
	title = {Multiscale modeling of human cerebrovasculature: {A} hybrid approach using image-based geometry and a mathematical algorithm},
	volume = {16},
	issn = {1553-7358},
	shorttitle = {Multiscale modeling of human cerebrovasculature},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1007943},
	doi = {10.1371/journal.pcbi.1007943},
	language = {en},
	number = {6},
	urldate = {2020-08-28},
	journal = {PLOS Computational Biology},
	author = {Ii, Satoshi and Kitade, Hiroki and Ishida, Shunichi and Imai, Yohsuke and Watanabe, Yoshiyuki and Wada, Shigeo},
	editor = {Beard, Daniel A},
	month = jun,
	year = {2020},
	pages = {e1007943},
	file = {Ii et al. - 2020 - Multiscale modeling of human cerebrovasculature A.pdf:C\:\\Users\\uqsboll2\\Zotero\\storage\\UPKCNWBM\\Ii et al. - 2020 - Multiscale modeling of human cerebrovasculature A.pdf:application/pdf},
}
