
@article{hanke_high-resolution_2014,
	title = {A high-resolution 7-{Tesla} {fMRI} dataset from complex natural stimulation with an audio movie},
	volume = {1},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata20143},
	doi = {10.1038/sdata.2014.3},
	abstract = {Abstract
            Here we present a high-resolution functional magnetic resonance (fMRI) dataset – 20 participants recorded at high field strength (7 Tesla) during prolonged stimulation with an auditory feature film (“Forrest Gump”). In addition, a comprehensive set of auxiliary data (T1w, T2w, DTI, susceptibility-weighted image, angiography) as well as measurements to assess technical and physiological noise components have been acquired. An initial analysis confirms that these data can be used to study common and idiosyncratic brain response patterns to complex auditory stimulation. Among the potential uses of this dataset are the study of auditory attention and cognition, language and music perception, and social perception. The auxiliary measurements enable a large variety of additional analysis strategies that relate functional response patterns to structural properties of the brain. Alongside the acquired data, we provide source code and detailed information on all employed procedures – from stimulus creation to data analysis. In order to facilitate replicative and derived works, only free and open-source software was utilized.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Scientific Data},
	author = {Hanke, Michael and Baumgartner, Florian J. and Ibe, Pierre and Kaule, Falko R. and Pollmann, Stefan and Speck, Oliver and Zinke, Wolf and Stadler, Jörg},
	month = may,
	year = {2014},
	pages = {140003},
	file = {Hanke et al. - 2014 - A high-resolution 7-Tesla fMRI dataset from comple.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/IQAUDYJ2/Hanke et al. - 2014 - A high-resolution 7-Tesla fMRI dataset from comple.pdf:application/pdf},
}

@article{tustison_n4itk_2010,
	title = {{N4ITK}: {Improved} {N3} {Bias} {Correction}},
	volume = {29},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{N4ITK}},
	url = {http://ieeexplore.ieee.org/document/5445030/},
	doi = {10.1109/TMI.2010.2046908},
	abstract = {A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as “N4ITK,” available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized 3 He lung image data, and 9.4T postmortem hippocampus data.},
	language = {en},
	number = {6},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tustison, Nicholas J and Avants, Brian B and Cook, Philip A and {Yuanjie Zheng} and Egan, Alexander and Yushkevich, Paul A and Gee, James C},
	month = jun,
	year = {2010},
	pages = {1310--1320},
	file = {Tustison et al. - 2010 - N4ITK Improved N3 Bias Correction.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/YDHPPXS7/Tustison et al. - 2010 - N4ITK Improved N3 Bias Correction.pdf:application/pdf},
}

@article{forstmann_multi-modal_2014,
	title = {Multi-modal ultra-high resolution structural 7-{Tesla} {MRI} data repository},
	volume = {1},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201450},
	doi = {10.1038/sdata.2014.50},
	abstract = {Abstract
            Structural brain data is key for the understanding of brain function and networks, i.e., connectomics. Here we present data sets available from the ‘atlasing of the basal ganglia (ATAG)’ project, which provides ultra-high resolution 7 Tesla (T) magnetic resonance imaging (MRI) scans from young, middle-aged, and elderly participants. The ATAG data set includes whole-brain and reduced field-of-view MP2RAGE and T2*-weighted scans of the subcortex and brainstem with ultra-high resolution at a sub-millimeter scale. The data can be used to develop new algorithms that help building high-resolution atlases both relevant for the basic and clinical neurosciences. Importantly, the present data repository may also be used to inform the exact positioning of electrodes used for deep-brain-stimulation in patients with Parkinson’s disease and neuropsychiatric diseases.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Scientific Data},
	author = {Forstmann, Birte U and Keuken, Max C and Schafer, Andreas and Bazin, Pierre-Louis and Alkemade, Anneke and Turner, Robert},
	month = dec,
	year = {2014},
	pages = {140050},
	file = {Forstmann et al. - 2014 - Multi-modal ultra-high resolution structural 7-Tes.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/5YCSRRCU/Forstmann et al. - 2014 - Multi-modal ultra-high resolution structural 7-Tes.pdf:application/pdf},
}

@inproceedings{cicek_2016,
	address = {Cham},
	title = {{3D} {U}-{Net}: {Learning} {Dense} {Volumetric} {Segmentation} from {Sparse} {Annotation}},
	volume = {9901},
	isbn = {978-3-319-46722-1 978-3-319-46723-8},
	shorttitle = {{3D} {U}-{Net}},
	url = {https://link.springer.com/10.1007/978-3-319-46723-8_49},
	abstract = {This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-ﬂy elastic deformations for eﬃcient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2016},
	publisher = {Springer International Publishing},
	author = {Çiçek, Özgün and Abdulkadir, Ahmed and Lienkamp, Soeren S. and Brox, Thomas and Ronneberger, Olaf},
	editor = {Ourselin, Sebastien and Joskowicz, Leo and Sabuncu, Mert R. and Unal, Gozde and Wells, William},
	year = {2016},
	doi = {10.1007/978-3-319-46723-8_49},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {424--432},
	file = {Çiçek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation f.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/BYEETFIM/Çiçek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation f.pdf:application/pdf},
}

@inproceedings{paszke_automatic_2017,
	address = {California},
	title = {Automatic differentiation in {PyTorch}},
	abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
	language = {en},
	booktitle = {{NIPS} 2017 {Autodiff} {Workshop}},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year = {2017},
	file = {Paszke et al. - Automatic differentiation in PyTorch.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/9IVE5RW5/Paszke et al. - Automatic differentiation in PyTorch.pdf:application/pdf},
}

@inproceedings{salehi_tversky_2017,
	title = {Tversky loss function for image segmentation using {3D} fully convolutional deep networks},
	url = {http://arxiv.org/abs/1706.05721},
	abstract = {Fully convolutional deep neural networks carry out excellent potential for fast and accurate image segmentation. One of the main challenges in training these networks is data imbalance, which is particularly problematic in medical imaging applications such as lesion segmentation where the number of lesion voxels is often much lower than the number of non-lesion voxels. Training with unbalanced data can lead to predictions that are severely biased towards high precision but low recall (sensitivity), which is undesired especially in medical applications where false negatives are much less tolerable than false positives. Several methods have been proposed to deal with this problem including balanced sampling, two step training, sample re-weighting, and similarity loss functions. In this paper, we propose a generalized loss function based on the Tversky index to address the issue of data imbalance and achieve much better trade-oﬀ between precision and recall in training 3D fully convolutional deep neural networks. Experimental results in multiple sclerosis lesion segmentation on magnetic resonance images show improved F2 score, Dice coeﬃcient, and the area under the precision-recall curve in test data. Based on these results we suggest Tversky loss function as a generalized framework to eﬀectively train deep neural networks.},
	language = {en},
	urldate = {2023-07-26},
	publisher = {arXiv},
	author = {Salehi, Seyed Sadegh Mohseni and Erdogmus, Deniz and Gholipour, Ali},
	year = {2017},
	note = {arXiv:1706.05721 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Salehi et al. - 2017 - Tversky loss function for image segmentation using.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/HCZUYGEC/Salehi et al. - 2017 - Tversky loss function for image segmentation using.pdf:application/pdf},
}

@article{chatterjee_ds6_2022,
	title = {{DS6}, {Deformation}-{Aware} {Semi}-{Supervised} {Learning}: {Application} to {Small} {Vessel} {Segmentation} with {Noisy} {Training} {Data}},
	volume = {8},
	issn = {2313-433X},
	shorttitle = {{DS6}, {Deformation}-{Aware} {Semi}-{Supervised} {Learning}},
	url = {https://www.mdpi.com/2313-433X/8/10/259},
	doi = {10.3390/jimaging8100259},
	abstract = {Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer’s disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi’s vessel enhancement with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them timeconsuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 ± 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.},
	language = {en},
	number = {10},
	urldate = {2023-07-26},
	journal = {Journal of Imaging},
	author = {Chatterjee, Soumick and Prabhu, Kartik and Pattadkal, Mahantesh and Bortsova, Gerda and Sarasaen, Chompunuch and Dubost, Florian and Mattern, Hendrik and De Bruijne, Marleen and Speck, Oliver and Nürnberger, Andreas},
	month = sep,
	year = {2022},
	pages = {259},
	file = {Chatterjee et al. - 2022 - DS6, Deformation-Aware Semi-Supervised Learning A.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/FDQCXP5K/Chatterjee et al. - 2022 - DS6, Deformation-Aware Semi-Supervised Learning A.pdf:application/pdf},
}

@article{manjon_adaptive_2010,
	title = {Adaptive non-local means denoising of {MR} images with spatially varying noise levels: {Spatially} {Adaptive} {Nonlocal} {Denoising}},
	volume = {31},
	issn = {10531807},
	shorttitle = {Adaptive non-local means denoising of {MR} images with spatially varying noise levels},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jmri.22003},
	doi = {10.1002/jmri.22003},
	abstract = {Purpose: To adapt the so-called nonlocal means ﬁlter to deal with magnetic resonance (MR) images with spatially varying noise levels (for both Gaussian and Rician distributed noise). Materials and Methods: Most ﬁltering techniques assume an equal noise distribution across the image. When this assumption is not met, the resulting ﬁltering becomes suboptimal. This is the case of MR images with spatially varying noise levels, such as those obtained by parallel imaging (sensitivity-encoded), intensity inhomogeneity-corrected images, or surface coil-based acquisitions. We propose a new method where information regarding the local image noise level is used to adjust the amount of denoising strength of the ﬁlter. Such information is automatically obtained from the images using a new local noise estimation method.
Results: The proposed method was validated and compared with the standard nonlocal means ﬁlter on simulated and real MRI data showing an improved performance in all cases.
Conclusion: The new noise-adaptive method was demonstrated to outperform the standard ﬁlter when spatially varying noise is present in the images.},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Manjón, José V. and Coupé, Pierrick and Martí-Bonmatí, Luis and Collins, D. Louis and Robles, Montserrat},
	month = jan,
	year = {2010},
	pages = {192--203},
	file = {Manjón et al. - 2010 - Adaptive non-local means denoising of MR images wi.pdf:/home/uqfribe1/snap/zotero-snap/common/Zotero/storage/BC4I6IX9/Manjón et al. - 2010 - Adaptive non-local means denoising of MR images wi.pdf:application/pdf},
}

@software{silversmith:2021,
  author       = {Silversmith, William},
  title        = {{cc3d: Connected components on multilabel 3D \& 2D 
                   images.}},
  month        = sep,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {3.2.1},
  doi          = {10.5281/zenodo.5719536},
  url          = {https://doi.org/10.5281/zenodo.5719536}
}